# OpenRouter API Configuration (for most models - Qwen, DeepSeek, Gemini, Grok)
OPENROUTER_API_KEY=sk-or-v1-your-api-key-here

# Anthropic API Configuration (for Claude models - used directly instead of OpenRouter)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# OpenAI API Configuration (for o4-mini model - not supported by OpenRouter)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Model Configuration
# Two-step generation: GENERATION_MODEL creates problems, SOLVER_MODEL solves them
# Using the same model is fine, but using different models can avoid shared blind spots
GENERATION_MODEL=anthropic/claude-opus-4
SOLVER_MODEL=anthropic/claude-opus-4
JUDGE_MODEL=anthropic/claude-opus-4
QWEN_MODEL=qwen/qwen3-max

# Cross-check models (PDF requirements mapped to actual OpenRouter model IDs)
# PDF spec: deepseek-v3.2, gemini-3-pro, grok-4-0709, o4-mini-2025-04-16
CROSSCHECK_MODELS=deepseek/deepseek-v3.2,google/gemini-3-pro-preview,x-ai/grok-4,openai/o4-mini-2025-04-16

# Generation Settings
TARGET_COUNT=25
MAX_CONCURRENT_REQUESTS=20
REQUESTS_PER_MINUTE=100

# Rate Limiting & Retries
# Higher values help survive rate limits when generating large batches (30+ QAs)
MAX_RETRIES=30

# Validation Thresholds
QWEN_MAX_PASS_RATE=0.05
MIN_CROSSCHECK_MODELS=2
MIN_CROSSCHECK_TOTAL=5
CORRECTNESS_THRESHOLD=0.90

# Qwen & Cross-check Samples
SAMPLES_PER_QWEN_CHECK=5
SAMPLES_PER_CROSSCHECK=5

# Output
OUTPUT_DIR=output
